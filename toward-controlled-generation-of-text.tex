\documentclass{beamer}
  \usepackage{tikz}
  \usepackage{amsmath}
  
  \usetikzlibrary{shapes,arrows,positioning,calc}
  \usetheme{metropolis}

  \title{Toward Controlled Generation of Text}
  \date{}
  \author{Hu, Yang, Liang, Salakhutdinov \& Xing}
  \institute{ICML 2017}

\begin{document}
  \maketitle

    \begin{frame}{Agenda}
      \begin{itemize}
      \item Motivation
      \item Background
      \item Method
      \item Experiments
      \item Results
      \end{itemize}
    \end{frame}

    \begin{frame}{Motivation}
      Interpretable latent space representations
      \begin{center}
        \begin{tabular}{ | c | c | c | c | }
          \hline
          0.21 & 0.32 & 0.74 & 0.43 \\  
          \hline
        \end{tabular}
      \end{center}
      {\Huge$$\Downarrow$$}
      \begin{center}
        \begin{tabular}{ | c | c | c | c | }
          \hline
          0.68 & 0.12 & 0.33 & {\color{red}\textbf{1.0}} \\  
          \hline
        \end{tabular}
      \end{center}
    \end{frame}

  \section{Method}
  \begin{frame}{Notation}
    \begin{itemize}
      \item $x \Rightarrow$ \textbf{source corpus}
      \item $\hat{x} \Rightarrow$ \textbf{output corpus}
      \item $c \Rightarrow$ \textbf{structured code} is a known label for each document
      \item $z \Rightarrow$ \textbf{unstructured latent code}
      \item $E \Rightarrow$ \textbf{encoder} parameterized to generate $z$, 
      \item $G \Rightarrow$ \textbf{decoder/generator} produces $\hat{x}$ conditioned on $(z, c)$.
      \item $D \Rightarrow$ \textbf{discriminator} predicts $c$ given $\hat{x}$.
    \end{itemize}
  \end{frame}

  \begin{frame}{Architecture}
    \tikzstyle{block} = [draw, rectangle, minimum height=2em]

    \begin{center}
    \begin{tikzpicture}[auto, node distance=1cm,>=latex']
        \node [block, name=input] (input) {$x$};
        \node [purple, block, right = of input] (encoder) {$E$};
        \node [block, right = of encoder] (latent) {$z$};
        \node [block, below = of latent] (code) {$c$};
        \node [block, right = of latent] (generator) {$G(z, c)$};
        \node [block, right = of generator] (output) {$\hat{x}$};
        \node [coordinate, above = of output] (inter1) {};
        \node [block, below = of output] (discriminator) {$D(c|\hat{x})$};

        \draw [->] (input) -- (encoder);
        \draw [->] (encoder) -- (latent);
        \draw [->] (latent) -- (generator);
        \draw [->] (code) -- (generator);
        \draw [->] (generator) -- (output);
        \draw [-] (output) -- (inter1);
        \draw [->] (inter1) -| (encoder);
        \draw [->] (output) -- (discriminator);
        \draw [->] (discriminator) -- (code);

        % Independence constraint
        \draw [red, dashed, ->] ($(inter1) + (-0.15,-0.15)$) -- ($(output) + (-0.15,0.45)$);
        \draw [red, dashed, ->] ($(output) + (-0.25,0.15)$) -- ($(generator) + (0.7,0.15)$);

        % Discriminator loss
        \draw [blue, dashed, ->] ($(discriminator) + (-0.15,0.45)$) -- ($(output) + (-0.15,-0.45)$);
        \draw [blue, dashed, ->] ($(output) + (-0.25,-0.15)$) -- ($(generator) + (0.7,-0.15)$);
    \end{tikzpicture}
  \end{center}
  \end{frame}

  \begin{frame}{Unrolled Architecture}
    \tikzstyle{block} = [draw, rectangle, minimum height=2em]
    \begin{center}
    \begin{tikzpicture}[auto, node distance=1.1cm,>=latex']
      \node [block, name=input] (input) {$x$};
      \node [purple, block, right = of input] (encoder1) {$E$};
      \node [block, right = of encoder1] (latent1) {$z$};
      \node [block, below = of latent1] (code) {$c$};
      \node [block, right = of latent1] (generator) {$G(z, c)$};
      \node [block, right = of generator] (output) {$\hat{x}$};
      \node [block, below = of output] (discriminator) {$D(c|\hat{x})$};
      \node [purple, block, right = of output] (encoder2) {$E$};
      \node [block, right = of encoder2] (latent2) {$\hat{z}$};

      \draw [->] (input) -- (encoder1);
      \draw [->] (encoder1) -- (latent1);
      \draw [->] (latent1) -- (generator);
      \draw [->] (code) -- (generator);
      \draw [->] (generator) -- (output);
      \draw [->] (output) -- (discriminator);
      \draw [->] (discriminator) -- (code);
      \draw [->] (output) -- (encoder2);
      \draw [->] (encoder2) -- (latent2);

      % Independence constraint
      \draw [red, dashed, ->] ($(encoder2) + (-0.8,0.15)$) -- ($(output) + (0.25,0.15)$);
      \draw [red, dashed, ->] ($(output) + (-0.25,0.15)$) -- ($(generator) + (0.7,0.15)$);

      % Discriminator loss
      \draw [blue, dashed, ->] ($(discriminator) + (-0.15,0.45)$) -- ($(output) + (-0.15,-0.45)$);
      \draw [blue, dashed, ->] ($(output) + (-0.25,-0.15)$) -- ($(generator) + (0.7,-0.15)$);
    \end{tikzpicture}
    \end{center}
  \end{frame}

  \begin{frame}{Training Objectives}
    \textbf{Reconstruction Loss} 
    
    Maximize the likelihood of predicting the original document $x$, given the latent spaces and the generator $G(z,c)$.
      \begin{eqnarray*}
        \mathcal{L}_{VAE}(\theta_G, \theta_E; x) &=& 
        - \mathbb{E}_{q_E(z|x)q_D(c|x)}[log P_G(x|z,c)] \\ & & 
        + KL(q_E(z|x)||P(z))
      \end{eqnarray*}
  \end{frame}

  \begin{frame}{Training Objectives}
    \textbf{Discriminator Loss} 
    \begin{itemize}
      \item Maximize the likelihood of predicting the correct distribution of the structured code $c$ given the labeled examples $X_L$.
      \begin{equation*}
        \mathcal{L}_S(\theta_D) = - \mathbb{E}_{X_L}[log q_D(c_L|x_L)]
      \end{equation*}
      \item Maximize the likelihood of predicting the correct distribution of the structured code $c$ given the generated sentences $\hat{x}$. Also minimize the empirically observed Shannon entropy of the observed discriminator prediction $q_D(c\prime|\hat{x})$, which reduces uncertainty and increases confidence of the structured code prediction.
    \end{itemize}
  \end{frame}

  \begin{frame}{Training Objectives}
    \textbf{Independence Constraint}
    
    The encoder from loss 1, is used to regenerate the latent distribution $z$ devoid of the structured code from the output distribution $\hat{x}$. Regardless of the structured code  $c$ that is currently present in either $x$ or $\hat{x}$, processing either through the generator should produce a consistent $z$. This allows the encoder to encode only latent factors that are independent of the structured code.
  \end{frame}

\end{document}
